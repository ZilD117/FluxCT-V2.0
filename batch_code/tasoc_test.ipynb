{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This script allows the user to create the data products and plots from FluxCT for multiple targets without using the webtool. \n",
    "\n",
    "INPUTS: \n",
    " --> The user will need to specify the directory path for code and plots. \n",
    " --> An input table of either KIC IDs with the format 'id' as the column name and comma separators. \n",
    "\n",
    "OUTPUTS: \n",
    " --> Downloaded fits file for the star from lightkurve to the plots directory. \n",
    " --> Downloaded plot created by FluxCT to the plots directory. \n",
    " --> Downloaded FluxCT data products to a .csv file.\n",
    "'''\n",
    "\n",
    "# Import modules\n",
    "from matplotlib import patches\n",
    "import time \n",
    "import pandas as pd  \n",
    "from lightkurve import search_targetpixelfile\n",
    "from astropy.wcs import WCS\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.io import fits \n",
    "import numpy as np\n",
    "from astroquery.gaia import Gaia\n",
    "from astropy.coordinates import SkyCoord\n",
    "import astropy.units as u\n",
    "import math\n",
    "from ast import literal_eval\n",
    "import ssl\n",
    "import lightkurve\n",
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "\n",
    "# print(os.getcwd()) In case you don't know what your current working dir is\n",
    "\n",
    "try:\n",
    "     _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    # Legacy Python that doesn't verify HTTPS certificates by default,\n",
    "    pass\n",
    "else:\n",
    "    # Handle target environment that doesn't support HTTPS verification,\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "# Paths and files \n",
    "code_file_path = './' # USER INPUT - Code directory \n",
    "plot_path = './plots/' # USER INPUT - Plot directory \n",
    "\n",
    "\n",
    "download_tasoc=\"./.lightkurve-cache/mastDownload/TESS/\"   # Downloading Path for FITS file from TASOC\n",
    "\n",
    "\n",
    "# Path to the TASOC directory\n",
    "tasoc2_directory = \"./.lightkurve-cache/mastDownload/TESS/\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3 stars in the sample.\n"
     ]
    }
   ],
   "source": [
    "identifiers = pd.read_csv(r\"C:\\Users\\User\\Desktop\\FluxCT\\FluxCT-V2.0\\test_star_list.csv\") # USER INPUT - KIC ID list  \n",
    "identifiers = list(identifiers['id'])\n",
    "print('There are ' + str(len(identifiers)) + ' stars in the sample.') \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTPF(object):\n",
    "    \"\"\"\n",
    "    Basic TPF class to give interactions similar to Lightkurve TargetPixelFiles\n",
    "\n",
    "    Attributes\n",
    "        filename (str): path to source file\n",
    "        flux (ndarray): 2D array of summed flux\n",
    "        pipeline_mask (ndarray): 2D boolean array indicated aperture pixels\n",
    "        wcs (astropy.wcs.WCS): world coordinate system from source file\n",
    "    \"\"\"\n",
    "    def __init__(self, filename):\n",
    "        \"\"\"\n",
    "        Read basic TPF information from a FITS file\n",
    "\n",
    "        Parameters:\n",
    "            filename (str): full path to FITS file\n",
    "        \"\"\"\n",
    "        with fits.open(filename) as hdul:\n",
    "            self.filename = filename\n",
    "            self.flux = hdul[2].data\n",
    "            self.pipeline_mask = (hdul[3].data & 2).astype(bool)\n",
    "            self.wcs = WCS(hdul[2])\n",
    "\n",
    "    @property\n",
    "    def shape(self):\n",
    "        \"\"\"Returns the (height, width) of the TPF.\n",
    "        \"\"\"\n",
    "        return self.flux.shape\n",
    "    \n",
    "    def get_central_coordinate(self):\n",
    "        \"\"\"Returns an astropy.coordinates.SkyCoord object with the TPF central coordinates\n",
    "        \"\"\"\n",
    "        h, w = self.shape\n",
    "        return self.wcs.pixel_to_world(w//2, h//2)\n",
    "    \n",
    "    def plot(self, ax=None, aperture_mask=\"pipeline\", mask_color=\"w\", **kw):\n",
    "        \"\"\"\n",
    "        Plot the TPF a la lightkurve.TargetPixelFile.plot\n",
    "\n",
    "        Parameters\n",
    "            ax (matplotlib axes object): axes to plot the TPF\n",
    "            aperture_mask (str or ndarray): boolean array for aperture\n",
    "            mask_color (str): color string for the aperture mask\n",
    "            kw: other keyword arguments for lightkurve.utils.plot_image\n",
    "\n",
    "        Returns\n",
    "            ax (matplotlib axes): the plot axes\n",
    "        \"\"\"\n",
    "        ax = lk.utils.plot_image(self.flux, ax=ax, **kw)\n",
    "\n",
    "        if aperture_mask is not None:\n",
    "            if aperture_mask == \"pipeline\":\n",
    "                aperture_mask = self.pipeline_mask\n",
    "            ax = self._plot_aperture(ax, aperture_mask, mask_color)\n",
    "\n",
    "        return ax\n",
    "\n",
    "    def _plot_aperture(self, ax, aperture_mask, mask_color=\"w\"):\n",
    "        \"\"\"Add the aperture mask to the existing TPF plot\n",
    "        \"\"\"\n",
    "        for i in range(aperture_mask.shape[0]):\n",
    "            for j in range(aperture_mask.shape[1]):\n",
    "                if aperture_mask[i, j]:\n",
    "                    xy = (j - 0.5, i - 0.5)\n",
    "                    rect = patches.Rectangle(\n",
    "                        xy=xy,\n",
    "                        width=1,\n",
    "                        height=1,\n",
    "                        color=mask_color,\n",
    "                        fill=False,\n",
    "                        hatch=\"//\",\n",
    "                    )\n",
    "                    ax.add_patch(rect)\n",
    "        return ax\n",
    "\n",
    "\n",
    "def get_tasoc_tpf(tic, sector=None):\n",
    "    \"\"\"\n",
    "    The full pipeline, from TIC ID to TESSCut TPF\n",
    "\n",
    "    Parameters\n",
    "        tic (int or str): TIC ID for target\n",
    "\n",
    "    Returns\n",
    "        tpf (TessTargetPixelFile): TESSCut-created TPF of target centered on\n",
    "            TASOC TPF central coordinate.\n",
    "    \"\"\"\n",
    "    sr = lightkurve.search_lightcurve(f\"TIC {tic}\", author=\"tasoc\", sector=sector)\n",
    "    lc = sr.download()\n",
    "    tpf0 = MyTPF(lc.filename)\n",
    "\n",
    "    coord = tpf0.get_central_coordinate()\n",
    "    sr = lightkurve.search_tesscut(coord, sector=sector)\n",
    "    tpf = sr.download(cutout_size=tpf0.shape)\n",
    "    tpf.pipeline_mask = tpf0.pipeline_mask\n",
    "    return tpf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning!!! lightkurve search for star 25132267 failed. No data found.\n"
     ]
    }
   ],
   "source": [
    "inputs = 'TIC 25132267'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Creating open lists for collecting data\n",
    "\n",
    "star_list = []\n",
    "gaia_source_list = []\n",
    "ra_list = []\n",
    "dec_list = []\n",
    "g_mag_list = []\n",
    "ruwe_list = []\n",
    "flux_list = []\n",
    "not_found = []\n",
    "\n",
    "error_list = []\n",
    "error_bool = False\n",
    "\n",
    "# Starting time counter \n",
    "t0 = time.time()\n",
    "a = 0\n",
    "\n",
    "numberID = inputs[4:] # Getting the number ID\n",
    "# Aperture Mask for TASOC \n",
    "download_dir=download_tasoc\n",
    "try: \n",
    "    sr = lightkurve.search_lightcurve(inputs, author=\"TASOC\")[0][::2]\n",
    "except IndexError:\n",
    "    error_bool = True\n",
    "    print(f'Warning!!! lightkurve search for star {numberID} failed. No data found.')\n",
    "\n",
    "\n",
    "if error_bool == False:\n",
    "    lc = sr.download(download_dir=download_dir)\n",
    "    sector = lc.sector\n",
    "\n",
    "    sr1 = sr[::2]  # each target has both a \"CBV\" and \"ENS\" light curve for each sector. \n",
    "                        # The TPF and aperture are the same for both, so you only need one.\n",
    "    tpf0 = MyTPF(lc.filename)\n",
    "    coord = tpf0.get_central_coordinate()\n",
    "\n",
    "\n",
    "    error_bool = False\n",
    "    \n",
    "    # Printing explanatory data  \n",
    "    \n",
    "    print(f'\\n********** {inputs[:3]} ' + str(numberID) + ' – Star Number ' + str(a) + ' **********') \n",
    "\n",
    "    if(len(sr)!=0):\n",
    "        print(f\"TASOC Searching Star {inputs} Complete\")\n",
    "        star_type = 'TIC'\n",
    "        # Find the first subdirectory in the download directory\n",
    "\n",
    "\n",
    "\n",
    "        sr = lightkurve.search_tesscut(coord, sector=sector)\n",
    "        tpf = sr.download(cutout_size=tpf0.shape)\n",
    "        print(tpf.pipeline_mask)\n",
    "        tpf_one = tpf[0]\n",
    "        tpf_one.to_fits(star_type + str(numberID) + '_fits.fits',overwrite=True)\n",
    "        ap = tpf0.pipeline_mask\n",
    "    if(len(sr)==0):\n",
    "                    print('Warning!!! Searching Failed. Star Not Found in Kepler/SPOC/TASOC')\n",
    "                    error_list.append(star_type + str(numberID))\n",
    "                    error_bool = True\n",
    "    if error_bool == False:\n",
    "\n",
    "        # Finding tpa\n",
    "        array = ap\n",
    "\n",
    "\n",
    "        # Finding the count of each pixel in the rows and columns of the mask. \n",
    "        row_count = np.count_nonzero(array, axis=1)\n",
    "        col_count = np.count_nonzero(array, axis=0) \n",
    "\n",
    "        # Columns = col are counting the x coordinate from left to right. \n",
    "        # This is the lower limit in pixel number for the left hand side of the array\n",
    "        # By adding 1 to the result I am removing the index to 0.\n",
    "        count_x = 0\n",
    "        if col_count[0] != 0:\n",
    "            count_x = 0\n",
    "        else:\n",
    "            for i in range(len(col_count)):\n",
    "                if col_count[i] == 0:\n",
    "                    count_x = i\n",
    "                else:\n",
    "                    count_x = count_x + 1\n",
    "                    break\n",
    "        \n",
    "        # Rows are counting the y coordinate from bottom to top.\n",
    "        # This is the lower limit in pixel number for the bottom of the array\n",
    "        # By adding 1 to the result I am removing the index to 0.\n",
    "        count_y = 0\n",
    "        if row_count[0] != 0:\n",
    "            count_y = 0\n",
    "        else:\n",
    "            for j in range(len(row_count)):\n",
    "                if row_count[j] == 0:\n",
    "                    count_y = j \n",
    "                else:\n",
    "                    count_y = count_y + 1\n",
    "                    break\n",
    "        \n",
    "        # Finding the top right pixel\n",
    "        array_2  = array[np.ix_(~np.all(array == False, axis=1), ~np.all(array == False, axis=0))]\n",
    "        tr_y = array_2.shape[0]  \n",
    "        tr_x = array_2.shape[1]  \n",
    "\n",
    "        # Top left pixel position \n",
    "        tl_x = count_x - 0.5\n",
    "        tl_y = count_y + tr_y - 1 + 0.5\n",
    "\n",
    "        # Bottom right pixel position \n",
    "        br_x = count_x + tr_x - 1 + 0.5\n",
    "        br_y = count_y - 0.5\n",
    "\n",
    "        # Bottom left pixel position\n",
    "        # Starts from the first pixel with a non-zero value so only include count_x and count_y \n",
    "        bl_x = count_x - 0.5\n",
    "        bl_y = count_y - 0.5\n",
    "\n",
    "        # Top right pixel position\n",
    "        # Already calaculated these so just add the 0.5\n",
    "        tr_x = count_x + tr_x - 1 + 0.5\n",
    "        tr_y = count_y + tr_y - 1 + 0.5 \n",
    "\n",
    "        # Pulling image to plot\n",
    "        tpf_data = fits.open(star_type + str(numberID) + '_fits.fits',memmap=False)\n",
    "        image = tpf_data[1].data\n",
    "        image = image['FLUX'][0]\n",
    "        wcs = WCS(tpf_data[2].header)\n",
    "\n",
    "        # Finding the corners of the aperture mask\n",
    "        tl = tpf_one.wcs.pixel_to_world(tl_x, tl_y)\n",
    "        tr = tpf_one.wcs.pixel_to_world(tr_x, tr_y)\n",
    "        bl = tpf_one.wcs.pixel_to_world(bl_x, bl_y)\n",
    "        br = tpf_one.wcs.pixel_to_world(br_x, br_y)\n",
    "\n",
    "        \n",
    "        tpf_data.close()\n",
    "\n",
    "        # Converting the corners of the aperture mask to coordinates for Gaia\n",
    "        top_left = wcs.world_to_pixel(tl)\n",
    "        top_right = wcs.world_to_pixel(tr)\n",
    "        bottom_left = wcs.world_to_pixel(bl)\n",
    "        bottom_right = wcs.world_to_pixel(br)\n",
    "\n",
    "        # Coordinates to search in Gaia \n",
    "        tr_ra = tr.ra.deg\n",
    "        tr_dec = tr.dec.deg\n",
    "        tl_ra = tl.ra.deg\n",
    "        tl_dec = tl.dec.deg\n",
    "        br_ra = br.ra.deg\n",
    "        br_dec = br.dec.deg\n",
    "        bl_ra = bl.ra.deg\n",
    "        bl_dec = bl.dec.deg\n",
    "\n",
    "        # Creating Gaia call\n",
    "        polygon = str(br_ra) + ', ' + str(br_dec) + ', ' + str(bl_ra) + ', ' + str(bl_dec) + ', ' + str(tl_ra) + ', ' + str(tl_dec) + ', ' + str(tr_ra) + ', ' + str(tr_dec)\n",
    "        columns = 'source_id, ra, dec, phot_g_mean_mag, ruwe, phot_g_mean_flux'\n",
    "        polygon_top10query_base = \"\"\"SELECT\n",
    "        {columns}\n",
    "        FROM gaiaedr3.gaia_source\n",
    "        WHERE 1=CONTAINS(\n",
    "                POINT(ra, dec), \n",
    "                POLYGON({polygon}))\n",
    "        \"\"\"\n",
    "\n",
    "        # Querying Gaia\n",
    "        polygon_top10query = polygon_top10query_base.format(columns=columns, \n",
    "                            polygon=polygon)\n",
    "\n",
    "        polygon_top10query_job = Gaia.launch_job_async(polygon_top10query)\n",
    "\n",
    "        polygon_top10query_results = polygon_top10query_job.get_results()\n",
    "\n",
    "        # Pulling data from Gaia\n",
    "        plot_source = list(polygon_top10query_results['source_id'])\n",
    "        plot_ra = list(polygon_top10query_results['ra'])\n",
    "        plot_dec = list(polygon_top10query_results['dec'])\n",
    "        phot = list(polygon_top10query_results['phot_g_mean_mag'])\n",
    "        ruwe = list(polygon_top10query_results['ruwe']) \n",
    "        flux = list(polygon_top10query_results['phot_g_mean_flux']) \n",
    "\n",
    "        # Initializing lists\n",
    "        plot_source_order = []\n",
    "        plot_ra_order = []\n",
    "        plot_dec_order = []\n",
    "        plot_ruwe_order = []\n",
    "        plot_phot_order = np.sort(phot)\n",
    "        plot_flux_order = []\n",
    "\n",
    "        # Putting the data in the correct order for plotting\n",
    "        for i in range(len(phot)):\n",
    "            if plot_phot_order[i] in phot:\n",
    "                index = phot.index(plot_phot_order[i])\n",
    "                plot_source_order.append(plot_source[index]) \n",
    "                plot_ra_order.append(plot_ra[index])\n",
    "                plot_dec_order.append(plot_dec[index])\n",
    "                plot_ruwe_order.append(ruwe[index]) \n",
    "                plot_flux_order.append(flux[index]) \n",
    "\n",
    "        # Saving final data lists for the output file\n",
    "        star_list.append(numberID)\n",
    "        ra_list.append(plot_ra_order) \n",
    "        dec_list.append(plot_dec_order) \n",
    "        gaia_source_list.append(plot_source_order) \n",
    "        ruwe_list.append(plot_ruwe_order) \n",
    "        flux_list.append(plot_flux_order) \n",
    "\n",
    "        # Removing nans from the photometry\n",
    "        plot_phot_order = [-999 if math.isnan(x) else x for x in plot_phot_order]\n",
    "        g_mag_list.append(plot_phot_order) \n",
    "\n",
    "        # Determining the coordinates of the companions for plotting\n",
    "        companions = SkyCoord(plot_ra_order, plot_dec_order, unit='deg')\n",
    "        companions_to_plot = wcs.world_to_pixel(companions)\n",
    "\n",
    "        # Making beautiful plot! \n",
    "        if len(companions_to_plot[0]) == 0: \n",
    "            not_found.append(numberID) \n",
    "        else: \n",
    "\n",
    "            # Setting figure\n",
    "            fig = plt.figure(figsize=(18, 15))\n",
    "            fig.add_subplot(111, projection = wcs) \n",
    "\n",
    "            # Plotting corners and box around TPA \n",
    "            top_line_x = [tl_x, tr_x]\n",
    "            top_line_y = [tl_y, tr_y]\n",
    "            plt.plot(top_line_x, top_line_y, linewidth=3, color='white')\n",
    "            bottom_line_x = [bl_x, br_x]\n",
    "            bottom_line_y = [bl_y, br_y]\n",
    "            plt.plot(bottom_line_x, bottom_line_y, linewidth=3, color='white')\n",
    "            left_line_x = [bl_x, tl_x]\n",
    "            left_line_y = [bl_y, tl_y]\n",
    "            plt.plot(left_line_x, left_line_y, linewidth=3, color='white')\n",
    "            right_line_x = [br_x, tr_x]\n",
    "            right_line_y = [br_y, tr_y]\n",
    "            plt.plot(right_line_x, right_line_y, linewidth=3, color='white')\n",
    "\n",
    "            # Plotting magnitudes \n",
    "            for i in range(len(phot)):\n",
    "                try:\n",
    "                    plt.text(companions_to_plot[0][i], companions_to_plot[1][i], str(round(plot_phot_order[i], 3)), color='#dd1c77', fontsize=25)\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "            # Plotting target star and companions\n",
    "            plt.scatter(companions_to_plot[0][1:], companions_to_plot[1][1:], marker='*', s=2000, color='white', edgecolor='black')\n",
    "            plt.scatter(companions_to_plot[0][0], companions_to_plot[1][0], marker='*', s=2000, color='pink', edgecolor='black')\n",
    "            \n",
    "            # Plotting corner text \n",
    "            plt.text(tr_x+0.2, tr_y+0.2, 'RA = ' + str(round(tr.ra.deg, 4)) + '\\nDec = ' + str(round(tr.dec.deg, 4)), fontsize=15, backgroundcolor='white') \n",
    "            plt.text(tl_x-1.8, tl_y+0.2, 'RA = ' + str(round(tl.ra.deg, 4)) + '\\nDec = ' + str(round(tl.dec.deg, 4)), fontsize=15, backgroundcolor='white') \n",
    "            plt.text(br_x+0.2, br_y+0.2, 'RA = ' + str(round(br.ra.deg, 4)) + '\\nDec = ' + str(round(br.dec.deg, 4)), fontsize=15, backgroundcolor='white') \n",
    "            plt.text(bl_x-1.8, bl_y+0.2, 'RA = ' + str(round(bl.ra.deg, 4)) + '\\nDec = ' + str(round(bl.dec.deg, 4)), fontsize=15, backgroundcolor='white') \n",
    "        \n",
    "            # Plotting corners\n",
    "            plt.scatter(tr_x, tr_y, s=200, marker='X', color='white') # Top right\n",
    "            plt.scatter(tl_x, tl_y, s=200, marker='X', color='white') # Top left\n",
    "            plt.scatter(br_x, br_y, s=200, marker='X', color='white') # Bottom right\n",
    "            plt.scatter(bl_x, bl_y, s=200, marker='X', color='white') # Bottom left\n",
    "\n",
    "            # Setting axes for ticks\n",
    "            ax = plt.gca()\n",
    "\n",
    "            # Plotting axes labels, titles, and images\n",
    "            plt.ylabel('DEC [degrees]', fontsize=20)\n",
    "            plt.xlabel('RA [hourangle]', fontsize=20)\n",
    "            plt.imshow(image, origin='lower', cmap='RdPu_r', alpha=1)\n",
    "            plt.imshow(array, origin='lower',  cmap='binary_r', alpha=0.2)\n",
    "            plt.title(f'{star_type} ' + str(numberID), fontsize=20)\n",
    "\n",
    "            # Setting tick parameters \n",
    "            ax.tick_params(axis='x', labelsize=20)\n",
    "            ax.tick_params(axis='y', labelsize=20)\n",
    "\n",
    "            # Plotting grid and saving the file\n",
    "            plt.grid(axis = 'both', color='grey', ls = ':', linewidth=6)\n",
    "            plt.show()\n",
    "\n",
    "            a = a + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "SearchResult containing 0 data products."
      ],
      "text/plain": [
       "SearchResult containing 0 data products."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sr = lightkurve.search_lightcurve(inputs, author=\"TASOC\")\n",
    "sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "548.5430479406101"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating open lists for collecting data\n",
    "star_list = []\n",
    "gaia_source_list = []\n",
    "ra_list = []\n",
    "dec_list = []\n",
    "g_mag_list = []\n",
    "ruwe_list = []\n",
    "flux_list = []\n",
    "not_found = []\n",
    "\n",
    "# Starting time counter \n",
    "t0 = time.time()\n",
    "a = 0\n",
    "star_type = ''\n",
    "error_list = []\n",
    "error_bool = False\n",
    "\n",
    "ap_size_list = []\n",
    "\n",
    "# Beginning process for i in the list \n",
    "for inputs in identifiers:\n",
    "    error_bool = False\n",
    "   \n",
    "    # Printing explanatory data  \n",
    "    numberID = inputs[4:] # Getting the number ID\n",
    "    print(f'\\n********** {inputs[:3]} ' + str(numberID) + ' – Star Number ' + str(a) + ' **********') \n",
    "   \n",
    "    # Removing Used FITS file for TIC. Necessary for each iteration. \n",
    "    if os.path.exists(tasoc2_directory):\n",
    "        # Remove the TASOC2 directory and all its contents\n",
    "        for item in os.listdir(tasoc2_directory):\n",
    "            item_path = os.path.join(tasoc2_directory, item)\n",
    "\n",
    "            # Check if it's a file or directory\n",
    "            if os.path.isfile(item_path):\n",
    "                os.remove(item_path)  # Remove the file\n",
    "            elif os.path.isdir(item_path):\n",
    "                shutil.rmtree(item_path)  # Remove the directory and its contents\n",
    "\n",
    "        print(f\"All files and folders within {tasoc2_directory} have been successfully deleted.\")\n",
    "    else:\n",
    "        print(f\"The directory {tasoc2_directory} does not exist.\")\n",
    "    \n",
    "    # Searching for tpf with lightkurve\n",
    "\n",
    "    if inputs[:3] == 'KIC':\n",
    "        tpf = search_targetpixelfile(inputs, author='Kepler').download_all()\n",
    "        tpf_one = tpf[0]\n",
    "        star_type = 'KIC'\n",
    "        m2 = tpf_one.to_fits(star_type + str(numberID) + '_fits.fits', overwrite=True)\n",
    "        ap = tpf_one.pipeline_mask\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "    elif inputs[:3] == 'TIC':\n",
    "        tpf = search_targetpixelfile(inputs, author='SPOC').download() # Try to download from SPOC first.\n",
    "        #tpf = None # For testing purposes. Uncomment to activate test mode.\n",
    "\n",
    "        if tpf !=None:\n",
    "            print(f\"Found Star {inputs} in SPOC\")\n",
    "            star_type = 'TIC'\n",
    "            tpf_one = tpf[0]\n",
    "            tpf_one.to_fits(star_type + str(numberID) + '_fits.fits',overwrite=True)\n",
    "            ap = tpf_one.pipeline_mask\n",
    "            \n",
    "        if tpf ==None: # SPOC search Failed. Try to doanload from TASOC.\n",
    "            print(f\"SPOC Failed for TIC {numberID}. Switching to TASOC...\")\n",
    "            \n",
    "            # Aperture Mask for TASOC \n",
    "            sr = lightkurve.search_lightcurve(inputs, author=\"TASOC\")\n",
    "            sr1 = sr[::2]  # each target has both a \"CBV\" and \"ENS\" light curve for each sector. \n",
    "                                # The TPF and aperture are the same for both, so you only need one.\n",
    "            download_dir=download_tasoc   # Downloading Path for FITS file from TASOC\n",
    "            sr2 = sr1.download_all(download_dir=download_dir) # directory for which you stores the downloaded files.\"\"\"\n",
    "\n",
    "            if(len(sr)!=0):\n",
    "                print(f\"TASOC Searching Star {inputs} Complete\")\n",
    "                star_type = 'TIC'\n",
    "                # Find the first subdirectory in the download directory\n",
    "                subdirectories = [d for d in os.listdir(download_dir) if os.path.isdir(os.path.join(download_dir, d))]\n",
    "                subdirectories.sort()  # Sort to get a consistent order\n",
    "                if subdirectories:\n",
    "                    first_subdir = os.path.join(download_dir, subdirectories[0])\n",
    "\n",
    "                    # Find the first FITS file in the first subdirectory\n",
    "                    fits_files = glob.glob(os.path.join(first_subdir, '**', '*.fits'), recursive=True)\n",
    "                    fits_files.sort()  # Sort to get a consistent order\n",
    "\n",
    "                    if fits_files:\n",
    "                        first_fits_file = fits_files[0]\n",
    "\n",
    "                        # Open the FITS file\n",
    "                        print(\"fits file opened in: \"+first_fits_file)\n",
    "                        tess_test = fits.open(first_fits_file,memmap=False)\n",
    "\n",
    "                        # Getting Aperture Mask \n",
    "                        tasoc_ap = tess_test[3].data\n",
    "                        ap = (tasoc_ap & 2).astype(bool)\n",
    "                        ap_size = len(ap)\n",
    "\n",
    "                        # Remember to close the file when done\n",
    "                        tess_test.close()\n",
    "\n",
    "                tpf = lightkurve.search_tesscut(inputs).download(cutout_size=ap_size)\n",
    "                tpf_one = tpf[0]\n",
    "                tpf_one.to_fits(star_type + str(numberID) + '_fits.fits',overwrite=True)\n",
    "            if(len(sr)==0):\n",
    "                print('Warning!!! Searching Failed. Star Not Found in Kepler/SPOC/TASOC')\n",
    "                error_list.append(star_type + str(numberID))\n",
    "                error_bool = True\n",
    "    if error_bool == False:\n",
    "         # Finding tpa\n",
    "        array = ap\n",
    "        ap_size_list.append(array)\n",
    "       \n",
    "\n",
    "# Timing code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
